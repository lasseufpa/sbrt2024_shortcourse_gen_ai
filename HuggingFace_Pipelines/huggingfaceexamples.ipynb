{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBRT 2024 - **An Introduction to Generative Artificial Intelligence with Applications in Telecommunications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (0.24.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abrkl\\anaconda3\\envs\\langchain_ai\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBrT'24 - Pipeline: Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I am a good person and I will be pleased as the opportunity comes,\" she says.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "res = generator(\"I am a good person and I will\",\n",
    "                max_length=300, num_return_sequences=1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBrT'24 - Pipeline: zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is my candidate: I support her because she is left-wing!', 'labels': ['politics', 'economy', 'education'], 'scores': [0.9677773118019104, 0.021402737125754356, 0.010819985531270504]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "res = classifier(\"This is my candidate: I support her because she is left-wing!\", \n",
    "\tcandidate_labels=[\"education\", \"politics\", \"economy\"])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBrT'24 - Pipeline: Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.999876856803894}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# High-level description\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "res = classifier(\"I am a good person!\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.999876856803894}]\n",
      "{'input_ids': [101, 1045, 2572, 1037, 2204, 2711, 999, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['i', 'am', 'a', 'good', 'person', '!']\n",
      "[1045, 2572, 1037, 2204, 2711, 999]\n",
      "i am a good person!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Detailed description\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "res = classifier(\"I am a good person!\")\n",
    "\n",
    "print(res)\n",
    "\n",
    "sequence = \"I am a good person!\"\n",
    "res = tokenizer(sequence)\n",
    "print(res)\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "\n",
    "decoded_string = tokenizer.decode(ids)\n",
    "print(decoded_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBrT'24 - Pipeline: Summarization\n",
    "\n",
    "About the \"do_sample\" parameter:\n",
    "\n",
    "do_sample=True: The model uses sampling to pick the next token in the sequence based on the probability distribution of all possible tokens. This introduces randomness, which can lead to more diverse and creative outputs.\n",
    "\n",
    "do_sample=False (default): The model uses greedy decoding or beam search. In greedy decoding, the model selects the token with the highest probability at each step, resulting in more deterministic outputs but potentially less variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Remo beat Paysandu 3-2 in the 9th round of the Brazilian Championship Series C . Remo took the provisional lead of group A with 16 points, against 15 for Santa Cruz .'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "text = \"\"\"Remo visited Paysandu this Saturday and won the Para classic game 3-2, in\n",
    "an electrifying duel for the 9th round of the Brazilian Championship Series C.\n",
    "In a lively second half, Leao opened the score 2-0 with Helio and Marlon, but\n",
    "saw Papao react and tie in the final minutes, with Wesley Matos and Nicolas.\n",
    "At 43, Wallace scored the third and sealed the victory. Remo won the classic game\n",
    "against Paysandu in Series C. With the result, Remo took the provisional lead\n",
    "of group A with 16 points, against 15 for Santa Cruz, who still plays in the\n",
    "round and can retake the lead. Paysandu, on the other hand, remained at 11 points,\n",
    "in 5th place, outside the zone of qualifying for the quarterfinals.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarizer(text, max_length=80, min_length=5)\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
