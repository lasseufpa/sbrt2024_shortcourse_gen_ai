{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SBRT 2024 - **An Introduction to Generative Artificial Intelligence with Applications in Telecommunications**\n",
        "\n",
        "### This python notebook was based in the code at https://github.com/WilliamYangXu/CSITransformer/, that comes from the paper called: [Transformer Empowered CSI Feedback for Massive MIMO Systems](https://ieeexplore.ieee.org/abstract/document/9602863)."
      ],
      "metadata": {
        "id": "559YkjSYFwsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset\n",
        "We have first to load the CSI matrix dataset, with 320000 samples, with dimension (320000, 2, 16, 32). Where the dimension are, respectively, the sample ID, image channel, image height and image width."
      ],
      "metadata": {
        "id": "bpv8krvaeYuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp8tjRnSC-AN",
        "outputId": "8ae94beb-ca4a-4e2f-c247-cdb153bd745d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a3afb73972c6261b82463960225c35cea23117d694d676012d5b66fbc1d8911b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import wget\n",
        "import os\n",
        "\n",
        "img_height = 16\n",
        "img_width = 32\n",
        "img_channels = 2\n",
        "\n",
        "class DatasetFolder(Dataset):\n",
        "\n",
        "    def __init__(self, matData):\n",
        "        self.matdata = matData\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.matdata.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.matdata[index]\n",
        "\n",
        "def load_data(\n",
        "        file_path,\n",
        "        shuffle = False,\n",
        "        train_test_ratio=0.8,\n",
        "        batch_size=32,\n",
        "        num_workers=0,\n",
        "        pin_memory=True,\n",
        "        drop_last=True):\n",
        "\n",
        "    if not os.path.isfile('Hdata.mat'):\n",
        "        url_train_dataset = 'https://nextcloud.lasseufpa.org/s/tjkmy5d6TjyKJ68/download/Hdata.mat'\n",
        "        filename = wget.download(url_train_dataset)\n",
        "\n",
        "    print(\"loading data...\")\n",
        "    mat = h5py.File('Hdata.mat', 'r')\n",
        "    data = np.transpose(mat['H_train'])\n",
        "    data = data.astype('float32')\n",
        "    data = np.reshape(data, [len(data), img_channels, img_height, img_width])\n",
        "\n",
        "    if shuffle:\n",
        "        data_copy = np.copy(data)\n",
        "        data_transpose = data_copy.transpose()\n",
        "        np.random.shuffle(data_transpose)\n",
        "        data_shuffle = data_transpose.transpose()\n",
        "\n",
        "    partition = int(data.shape[0] * train_test_ratio)\n",
        "    x_train, x_test = data[:partition], data[partition:]\n",
        "    x_train_shuffle, x_test_shuffle = data_shuffle[:partition], data_shuffle[partition:]\n",
        "\n",
        "    # dataLoader for training\n",
        "    train_dataset = DatasetFolder(x_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                               shuffle=True, num_workers=num_workers,\n",
        "                                               pin_memory=pin_memory, drop_last=drop_last)\n",
        "    # dataLoader for validating\n",
        "    test_dataset = DatasetFolder(x_test)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                              shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "    if shuffle:\n",
        "        train_shuffle_dataset = DatasetFolder(x_train_shuffle)\n",
        "        train_shuffle_loader = torch.utils.data.DataLoader(train_shuffle_dataset, batch_size=batch_size,\n",
        "                                                  shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "        test_shuffle_dataset = DatasetFolder(x_test_shuffle)\n",
        "        test_shuffle_loader = torch.utils.data.DataLoader(test_shuffle_dataset, batch_size=batch_size,\n",
        "                                                          shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "\n",
        "        return train_loader, test_loader, train_dataset, test_dataset, train_shuffle_loader, test_shuffle_loader, train_shuffle_dataset, test_shuffle_dataset\n",
        "\n",
        "    return train_loader, test_loader, train_dataset, test_dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "1aG-Oq1XfCd7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DL-based CSI Methods\n",
        "\n",
        "Here we have all classes to construct the CSITransformer and MixedCSI architectures."
      ],
      "metadata": {
        "id": "8sn_cRnQe27z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=True)\n",
        "\n",
        "class ConvBN(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, groups=1):\n",
        "        if not isinstance(kernel_size, int):\n",
        "            padding = [(i - 1) // 2 for i in kernel_size]\n",
        "        else:\n",
        "            padding = (kernel_size - 1) // 2\n",
        "        super(ConvBN, self).__init__(OrderedDict([\n",
        "            ('conv', nn.Conv2d(in_planes, out_planes, kernel_size, stride,\n",
        "                               padding=padding, groups=groups, bias=False)),\n",
        "            ('bn', nn.BatchNorm2d(out_planes)),\n",
        "            ('LeakyReLU', nn.LeakyReLU(negative_slope=0.3, inplace=False))\n",
        "        ]))\n",
        "\n",
        "class ConvBN_linear(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, groups=1):\n",
        "        if not isinstance(kernel_size, int):\n",
        "            padding = [(i - 1) // 2 for i in kernel_size]\n",
        "        else:\n",
        "            padding = (kernel_size - 1) // 2\n",
        "        super(ConvBN_linear, self).__init__(OrderedDict([\n",
        "            ('conv', nn.Conv2d(in_planes, out_planes, kernel_size, stride,\n",
        "                               padding=padding, groups=groups, bias=False)),\n",
        "            ('bn', nn.BatchNorm2d(out_planes))\n",
        "        ]))\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, ch, nblocks=1, shortcut=True):\n",
        "        super().__init__()\n",
        "        self.shortcut = shortcut\n",
        "        self.module_list = nn.ModuleList()\n",
        "        for i in range(nblocks):\n",
        "            resblock_one = nn.ModuleList()\n",
        "            resblock_one.append(ConvBN(ch, 8, 3))\n",
        "            resblock_one.append(ConvBN(8, 16, 3))\n",
        "            resblock_one.append(ConvBN_linear(16, ch, 3))\n",
        "            self.module_list.append(resblock_one)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for module in self.module_list:\n",
        "            h = x\n",
        "            for res in module:\n",
        "                h = res(h)\n",
        "            x = x + h if self.shortcut else h\n",
        "        return x\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "\n",
        "    def __init__(self, H=16, W=32, patch_size=4, in_chans=2, embed_dim=32):\n",
        "        super().__init__()\n",
        "        num_patches = H * W / patch_size ** 2\n",
        "        self.img_size = [H, W]\n",
        "        self.patch_size = [patch_size, patch_size]\n",
        "        self.num_patches = num_patches\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, max_length=5000):\n",
        "        super(FixedPositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_length, embedding_dim)\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, embedding_dim, 2).float()\n",
        "            * (-torch.log(torch.tensor(10000.0)) / embedding_dim)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(torch.nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout, feedforward_dim):\n",
        "        super().__init__()\n",
        "        self.attn = torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "        self.linear_1 = torch.nn.Linear(embed_dim, feedforward_dim)\n",
        "        self.linear_2 = torch.nn.Linear(feedforward_dim, embed_dim)\n",
        "        self.layernorm_1 = torch.nn.LayerNorm(embed_dim)\n",
        "        self.layernorm_2 = torch.nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        attn_out, _ = self.attn(x_in, x_in, x_in)\n",
        "        x = self.layernorm_1(x_in + attn_out)\n",
        "        ff_out = self.linear_2(torch.nn.functional.relu(self.linear_1(x)))\n",
        "        x = self.layernorm_2(x + ff_out)\n",
        "        return x\n",
        "\n",
        "class Csi_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_Encoder, self).__init__()\n",
        "\n",
        "        self.convban = nn.Sequential(OrderedDict([\n",
        "            (\"conv3x3_bn\", ConvBN_linear(1, 2, 1)),\n",
        "        ]))\n",
        "        self.fc = nn.Linear(2048, int(feedback_bits))\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        x_in = x_in.view(32,1,32,32)\n",
        "        out = self.convban(x_in)\n",
        "        out = out.view(32,-1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "class Csi_Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_Decoder, self).__init__()\n",
        "\n",
        "        self.feedback_bits = feedback_bits\n",
        "        self.fc = nn.Linear(int(feedback_bits), 1024)\n",
        "        decoder = OrderedDict([\n",
        "            (\"decoder1\",ResBlock(1)),\n",
        "            ('LeakyReLU', nn.LeakyReLU(negative_slope=0.3, inplace=False)),\n",
        "            (\"decoder2\",ResBlock(1))\n",
        "        ])\n",
        "        self.decoder_feature = nn.Sequential(decoder)\n",
        "        self.out_cov = ConvBN_linear(1,1,3)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.fc(out)\n",
        "        out = out.view(32, 1, -1, 32)\n",
        "        out = self.decoder_feature(out)\n",
        "        out = self.out_cov(out)\n",
        "        out = self.sig(out)\n",
        "        out = out.view(32,2,16,32)\n",
        "        return out\n",
        "\n",
        "class Csi_Attention_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_Attention_Encoder, self).__init__()\n",
        "\n",
        "        # with positional encoding\n",
        "        # self.patch_embedding = nn.Sequential(OrderedDict([\n",
        "        #     (\"patch_embedding\", PatchEmbed(H=16, W=32, patch_size=4, in_chans=2, embed_dim=32))\n",
        "        # ]))\n",
        "        # self.positional_encoding = nn.Sequential(OrderedDict([\n",
        "        #     (\"positional_encoding\", FixedPositionalEncoding(32,32))\n",
        "        # ]))\n",
        "        # self.transformer_layer =  nn.Sequential(OrderedDict([\n",
        "        #     (\"transformer_encoder1\", TransformerEncoder(32,8,0,512)) # after [32, 512, 32]\n",
        "        # ])) # for added positional encoding\n",
        "\n",
        "        # without positional encoding\n",
        "        self.conv_layer = ConvBN_linear(1,2,1)\n",
        "        self.transformer_layer = nn.Sequential(OrderedDict([\n",
        "\n",
        "                (\"transformer_encoder1\", TransformerEncoder(64,8,0,512))\n",
        "            ])) # without positional encoding\n",
        "        self.fc = nn.Linear(2048, int(feedback_bits))\n",
        "\n",
        "    def forward(self, x_in):\n",
        "\n",
        "        # with pos encoding\n",
        "        ##x_in = self.patch_embedding(x_in)\n",
        "        ##x_in = self.positional_encoding(x_in)\n",
        "        # without pos encoding\n",
        "        x_in = x_in.view(32,1,32,32)\n",
        "        x_in = self.conv_layer(x_in)\n",
        "\n",
        "        x_in = x_in.view(32,32,64)\n",
        "        out = self.transformer_layer(x_in)\n",
        "        #out = out.contiguous().view(32,-1) with pos encoding\n",
        "        out = out.contiguous().view(-1, 2048) # without pos encoding\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "class Csi_Attention_Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_Attention_Decoder, self).__init__()\n",
        "\n",
        "        self.feedback_bits = feedback_bits\n",
        "        self.fc = nn.Linear(int(feedback_bits), 2048)\n",
        "        decoder = OrderedDict([\n",
        "            (\"transformer_decoder1\",TransformerEncoder(64,8,0,feedforward_dim=128))\n",
        "        ])\n",
        "        self.decoder_feature = nn.Sequential(decoder)\n",
        "        self.conv_linear = ConvBN_linear(2,1,1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.fc(out)\n",
        "        out = out.view(32, -1, 64)\n",
        "        out = self.decoder_feature(out)\n",
        "        out = out.view([32,2,32,32])\n",
        "        out = self.conv_linear(out)\n",
        "        out = self.sig(out)\n",
        "        out = out.view(32,2,16,32)\n",
        "        return out\n",
        "\n",
        "class Csi_Net(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_Net, self).__init__()\n",
        "        self.encoder = Csi_Encoder(feedback_bits)\n",
        "        self.decoder = Csi_Decoder(feedback_bits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.encoder(x)\n",
        "        out = self.decoder(feature)\n",
        "        return out\n",
        "\n",
        "class Csi_Transformer_Net(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_Transformer_Net, self).__init__()\n",
        "        self.encoder = Csi_Attention_Encoder(feedback_bits)\n",
        "        self.decoder = Csi_Attention_Decoder(feedback_bits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.encoder(x)\n",
        "        out = self.decoder(feature)\n",
        "        return out\n",
        "\n",
        "class CS_Net(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(CS_Net, self).__init__()\n",
        "        self.A = np.random.uniform(low=-0.5, high=0.5, size=(1024, feedback_bits))\n",
        "        self.A = torch.from_numpy(self.A)\n",
        "        self.A = self.A.float()\n",
        "        self.decoder = Csi_Decoder(feedback_bits)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(32, -1)\n",
        "        out = x @ self.A\n",
        "        out = out\n",
        "        out = self.decoder(out)\n",
        "        return out\n",
        "\n",
        "class Csi_CNN_Transformer_Net(nn.Module):\n",
        "\n",
        "    def __init__(self, feedback_bits):\n",
        "        super(Csi_CNN_Transformer_Net, self).__init__()\n",
        "        self.encoder = Csi_Encoder(feedback_bits)\n",
        "        self.decoder = Csi_Attention_Decoder(feedback_bits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.encoder(x)\n",
        "        out = self.decoder(feature)\n",
        "        return ou"
      ],
      "metadata": {
        "id": "bvX572tOe8Ps"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Segmentation"
      ],
      "metadata": {
        "id": "VtsWlzsJetIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gpu_list = '0'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_list\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def channel_visualization(image):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image, cmap=plt.cm.gray, interpolation='nearest', origin='upper')\n",
        "    ax.spines['left'].set_position(('outward', 10))\n",
        "    ax.spines['bottom'].set_position(('outward', 10))\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    ax.xaxis.set_ticks_position('bottom')\n",
        "    plt.show()\n",
        "\n",
        "SEED = 42\n",
        "print(\"seeding everything...\")\n",
        "seed_everything(SEED)\n",
        "print(\"initializing parameters...\")\n",
        "\n",
        "\n",
        "class model_trainer():\n",
        "\n",
        "    def __init__(self,\n",
        "                 epochs,\n",
        "                 net,\n",
        "                 feedbackbits=128,\n",
        "                 batch_size=32,\n",
        "                 learning_rate=1e-3,\n",
        "                 lr_decay_freq=30,\n",
        "                 lr_decay=0.1,\n",
        "                 best_loss=100,\n",
        "                 num_workers=0,\n",
        "                 print_freq=100,\n",
        "                 train_test_ratio=0.8):\n",
        "\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lr_decay_freq = lr_decay_freq\n",
        "        self.lr_decay = lr_decay\n",
        "        self.best_loss = best_loss\n",
        "        self.num_workers = num_workers\n",
        "        self.print_freq = print_freq\n",
        "        self.train_test_ratio = train_test_ratio\n",
        "        # parameters for data\n",
        "        self.feedback_bits = feedbackbits\n",
        "        self.img_height = 16\n",
        "        self.img_width = 32\n",
        "        self.img_channels = 2\n",
        "\n",
        "        self.model = eval(net)(self.feedback_bits)\n",
        "        self.x_label = []\n",
        "        self.y_label = []\n",
        "        self.ys_label = []\n",
        "        self.t_label = []\n",
        "\n",
        "        if len(gpu_list.split(',')) > 1:\n",
        "            self.model = torch.nn.DataParallel(self.model)  # model.module\n",
        "        else:\n",
        "            self.model = self.model\n",
        "\n",
        "        self.criterion = NMSELoss(reduction='mean')  # nn.MSELoss()\n",
        "        self.criterion_test = NMSELoss(reduction='sum')\n",
        "        # self.criterion_rho = CosSimilarity(reduction='mean')\n",
        "        # self.criterion_test_rho = CosSimilarity(reduction='sum')\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        # train_loader, test_loader, train_dataset, test_dataset, \\\n",
        "        # train_shuffle_loader, test_shuffle_loader, train_shuffle_dataset, test_shuffle_dataset\n",
        "\n",
        "        self.train_loader, self.test_loader, self.train_dataset,        self.test_dataset, self.train_shuffle_loader, self.test_shuffle_loader,        self.train_shuffle_dataset, self.test_shuffle_dataset =             load_data('/filepath',shuffle = True)\n",
        "\n",
        "    def model_save(self,encoderPATH, decoderPATH):\n",
        "        print('Saving model...')\n",
        "\n",
        "        try:\n",
        "            torch.save({'state_dict': self.model.encoder.state_dict(), }, '/filepath')\n",
        "        except:\n",
        "            torch.save({'state_dict': self.model.module.encoder.state_dict(), }, '/filepath')\n",
        "\n",
        "        try:\n",
        "            torch.save({'state_dict': self.model.decoder.state_dict(), }, '/filepath')\n",
        "        except:\n",
        "            torch.save({'state_dict': self.model.module.decoder.state_dict(), }, '/filepath')\n",
        "#         print('Model saved!')\n",
        "        self.best_loss = self.average_loss\n",
        "\n",
        "    def model_train(self):\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            print('========================')\n",
        "            print('lr:%.4e' % self.optimizer.param_groups[0]['lr'])\n",
        "            # train model\n",
        "            self.model.train()\n",
        "\n",
        "            # decay lr\n",
        "            if epoch % self.lr_decay_freq == 0 and epoch > 0:\n",
        "                self.optimizer.param_groups[0]['lr'] = self.optimizer.param_groups[0]['lr'] * self.lr_decay\n",
        "\n",
        "            # training...\n",
        "            for i, input in enumerate(self.train_loader):\n",
        "                input = input  # input [batch=32,2,16,32]\n",
        "                output = self.model(input)\n",
        "                loss = self.criterion(output, input)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "                if i % self.print_freq == 0:\n",
        "                    print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                          'Loss {loss:.4f}\\t'.format(\n",
        "                        epoch, i, len(self.train_loader), loss=loss.item()))\n",
        "            self.model.eval()\n",
        "\n",
        "            # evaluating...\n",
        "            self.total_loss = 0\n",
        "            self.total_rho = 0\n",
        "            start = time.time()\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for i, input in enumerate(self.test_loader):\n",
        "\n",
        "                    input = input\n",
        "                    output = self.model(input)\n",
        "                    self.total_loss += self.criterion_test(output, input).item()\n",
        "                    # self.total_rho += self.criterion_rho(output,input).item()\n",
        "                    #print(rho(output,input), type(rho(output,input)))\n",
        "                    self.total_rho += (rho(output,input))\n",
        "\n",
        "                end = time.time()\n",
        "                t = end - start\n",
        "                self.average_loss = self.total_loss / len(self.test_dataset)\n",
        "                self.average_rho = self.total_rho / len(list(enumerate(self.test_loader)))\n",
        "                self.x_label.append(epoch)\n",
        "                self.y_label.append(self.average_loss)\n",
        "                self.t_label.append(t)\n",
        "                print('NMSE %.4f ρ %.3f time %.3f' % (self.average_loss,self.average_rho, t))\n",
        "\n",
        "        for i, input in enumerate(self.test_loader): # visualize one sample\n",
        "            if i == 3: # set shuffle = False to ensure the same sample each time\n",
        "                ones = torch.ones(32,32)\n",
        "                image1 = input[0].view(32,32)\n",
        "                image1 = ones - image1\n",
        "                image1 = image1.numpy()\n",
        "                channel_visualization(image1)\n",
        "                input = input\n",
        "                output = self.model(input)\n",
        "                output = output.cpu()\n",
        "                image2 = output[0].view(32,32)\n",
        "                image2 = ones - image2\n",
        "                image2 = image2.detach().numpy()\n",
        "                channel_visualization(image2)\n",
        "\n",
        "        return self.x_label, self.y_label, sum(self.t_label)/len(self.t_label) # , self.ys_label\n"
      ],
      "metadata": {
        "id": "A6SGUyR9evCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11122744-6d34-4dc0-bd57-13ce3c02601c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seeding everything...\n",
            "initializing parameters...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss function and Metrics"
      ],
      "metadata": {
        "id": "O0iGzkhned5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NMSE(x, x_hat):\n",
        "    x_real = np.reshape(x[:, :, :, 0], (len(x), -1))\n",
        "    x_imag = np.reshape(x[:, :, :, 1], (len(x), -1))\n",
        "    x_hat_real = np.reshape(x_hat[:, :, :, 0], (len(x_hat), -1))\n",
        "    x_hat_imag = np.reshape(x_hat[:, :, :, 1], (len(x_hat), -1))\n",
        "    x_C = x_real - 0.5 + 1j * (x_imag - 0.5)\n",
        "    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n",
        "    power = np.sum(abs(x_C) ** 2, axis=1)\n",
        "    mse = np.sum(abs(x_C - x_hat_C) ** 2, axis=1)\n",
        "    nmse = np.mean(mse / power)\n",
        "    return nmse\n",
        "\n",
        "def NMSE_cuda(x, x_hat):\n",
        "    x_real = x[:, 0, :, :].view(len(x), -1) - 0.5\n",
        "    x_imag = x[:, 1, :, :].view(len(x), -1) - 0.5\n",
        "    x_hat_real = x_hat[:, 0, :, :].contiguous().view(len(x_hat), -1) - 0.5\n",
        "    x_hat_imag = x_hat[:, 1, :, :].contiguous().view(len(x_hat), -1) - 0.5\n",
        "    power = torch.sum(x_real ** 2 + x_imag ** 2, axis=1)\n",
        "    mse = torch.sum((x_real - x_hat_real) ** 2 + (x_imag - x_hat_imag) ** 2, axis=1)\n",
        "    nmse = mse / power\n",
        "    return nmse\n",
        "\n",
        "class NMSELoss(nn.Module):\n",
        "    def __init__(self, reduction='sum'):\n",
        "        super(NMSELoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, x_hat, x):\n",
        "        nmse = NMSE_cuda(x, x_hat)\n",
        "        if self.reduction == 'mean':\n",
        "            nmse = torch.mean(nmse)\n",
        "        else:\n",
        "            nmse = torch.sum(nmse)\n",
        "        return nmse\n",
        "\n",
        "def rho(x, x_hat):\n",
        "    x_real = x[:, 0, :, :].view(len(x), -1) - 0.5\n",
        "    x_imag = x[:, 1, :, :].view(len(x), -1) - 0.5\n",
        "    x_hat_real = x_hat[:, 0, :, :].contiguous().view(len(x_hat), -1) - 0.5\n",
        "    x_hat_imag = x_hat[:, 1, :, :].contiguous().view(len(x_hat), -1) - 0.5\n",
        "\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=0)\n",
        "    out_real = cos(x_real,x_hat_real)\n",
        "    out_imag = cos(x_imag, x_hat_imag)\n",
        "    result_real = out_real.sum() / len(out_real)\n",
        "    reault_imag = out_imag.sum() / len(out_imag)\n",
        "    return 0.5*(result_real + reault_imag)\n",
        "\n",
        "class CosSimilarity(nn.Module):\n",
        "    def __init__(self, reduction='sum'):\n",
        "        super(CosSimilarity, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, x_hat, x):\n",
        "        cos = rho(x, x_hat)\n",
        "        # if self.reduction == 'mean':\n",
        "        #     cos = torch.mean(cos)\n",
        "        # else:\n",
        "        #     cos = torch.sum(cos)\n",
        "        return cos\n"
      ],
      "metadata": {
        "id": "7TjO4Y-1elwi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training CSINet and CSITransformer"
      ],
      "metadata": {
        "id": "E9QFBcP_eNxP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6udGvkUd5Ay"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "gpu_list = '0'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_list\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 42\n",
        "seed_everything(SEED)\n",
        "\n",
        "def train_all(bits):\n",
        "    print(\"=\"*30)\n",
        "    print(\"Encoder: transformer; Decoder: transformer\")\n",
        "    print(\"compressed codeword bits: {}\".format(bits))\n",
        "    agent1 = model_trainer(epochs=40, net=\"Csi_Transformer_Net\",feedbackbits=bits)\n",
        "    x1, agent1_NMSE, t1 = agent1.model_train()\n",
        "    print(\"Csi_Transformer_Net\")\n",
        "    print(agent1_NMSE)\n",
        "    print(\"average time used is:\", t1)\n",
        "    plt.plot(x1, agent1_NMSE, label=\"Csi_Transformer_Net\")\n",
        "\n",
        "    print(\"=\"*30)\n",
        "    print(\"Encoder: CNN; Decoder: transformer\")\n",
        "    print(\"compressed codeword bits: {}\".format(bits))\n",
        "    agent2 = model_trainer(epochs=40, net=\"Csi_CNN_Transformer_Net\",feedbackbits=bits)\n",
        "    x2, agent2_NMSE, t2 = agent2.model_train()\n",
        "    print(\"Csi_CNN_Transformer_Net\")\n",
        "    print(agent2_NMSE)\n",
        "    print(\"average time used is:\", t2)\n",
        "    plt.plot(x2, agent2_NMSE, label=\"Csi_CNN_Transformer_Net\")\n",
        "\n",
        "    print(x2)\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(x1, agent1_NMSE, label=\"Csi_Transformer_Net\")\n",
        "    plt.plot(x2, agent2_NMSE, label=\"Csi_CNN_Transformer_Net\")\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"NMSE\")\n",
        "    plt.show()\n",
        "\n",
        "# train_all(256)\n",
        "train_all(128)\n",
        "# train_all(64)\n",
        "# train_all(32)\n"
      ]
    }
  ]
}